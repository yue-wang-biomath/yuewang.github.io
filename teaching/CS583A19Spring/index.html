<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
  /*
   * Copyright 2013 Christophe-Marie Duquesne <chmd@chmd.fr>
   *
   * CSS for making a resume with pandoc. Inspired by moderncv.
   *
   * This CSS document is delivered to you under the CC BY-SA 3.0 License.
   * https://creativecommons.org/licenses/by-sa/3.0/deed.en_US
   */
  
  /* Whole document */
  body {
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
      width: 800px;
      margin: auto;
      background: #FFFFFF;
      padding: 10px 10px 10px 10px;
  }
  
  /* Title of the resume */
  h1 {
      font-size: 55px;
      color: #757575;
      text-align:center;
      margin-bottom:15px;
  }
  h1:hover {
      background-color: #757575;
      color: #FFFFFF;
      text-shadow: 1px 1px 1px #333;
  }
  
  /* Titles of categories */
  h2 {
      /* This is called "sectioncolor" in the ConTeXt stylesheet. */
      color: #397249;
  }
  /* There is a bar just before each category */
  h2:before {
      content: "";
      display: inline-block;
      margin-right:1%;
      width: 16%;
      height: 10px;
      /* This is called "rulecolor" in the ConTeXt stylesheet. */
      background-color: #9CB770;
  }
  h2:hover {
      background-color: #397249;
      color: #FFFFFF;
      text-shadow: 1px 1px 1px #333;
  }
  
  /* Definitions */
  dt {
      float: left;
      clear: left;
      width: 17%;
      /*font-weight: bold;*/
  }
  dd {
      margin-left: 17%;
  }
  p {
      margin-top:0;
      margin-bottom:7px;
  }
  
  /* Blockquotes */
  blockquote {
      text-align: center
  }
  
  /* Links */
  a {
      text-decoration: none;
      color: #397249;
  }
  a:hover, a:active {
      background-color: #397249;
      color: #FFFFFF;
      text-decoration: none;
      text-shadow: 1px 1px 1px #333;
  }
  
  /* Horizontal separators */
  hr {
      color: #A6A6A6;
  }
  
  table {
      width: 100%;
  }
  </style>
</head>
<body>
<h1 id="cs583-deep-learning">CS583: Deep Learning</h1>
<blockquote>
<p>Instructor: Shusen Wang</p>
</blockquote>
<blockquote>
<p>TA: Yao Xiao</p>
</blockquote>
<h2 id="description">Description</h2>
<p><strong>Meeting Time:</strong></p>
<ul>
<li><p>Thursday, 6:30 - 9:00 PM, Peirce Complex 116</p></li>
<li><p><strong>The classes on these dates are canceled: Jan 31</strong></p></li>
</ul>
<p><strong>Office Hours:</strong></p>
<ul>
<li><p>Thursday, 3:00 - 5:00 PM, North Building 205</p></li>
<li><p><strong>The office hours on these dates are canceled: Jan 31, Feb 28</strong></p></li>
<li><p>Time change: 3-5PM, May 2 ==&gt; 2-6PM, May 1</p></li>
<li><p>Time change: May 9 ==&gt; both May 7 and 8</p></li>
</ul>
<p><strong>Contact the Instructor:</strong></p>
<ul>
<li><p>For questions regarding grading, talk to the instructor during office hours or send him emails.</p></li>
<li><p>For any other questions, come during the office hours; the instructor will NOT reply such emails.</p></li>
</ul>
<p><strong>Prerequisite:</strong></p>
<ul>
<li><p>Elementary linear algebra, e.g., matrix multiplication, eigenvalue decomposition, and matrix norms.</p></li>
<li><p>Elementary calculus, e.g., convex function, differentiation of scalar functions, first derivative, and second derivative.</p></li>
<li><p>Python programming (especially the Numpy library) and Jupyter Notebook.</p></li>
</ul>
<p><strong>Goal:</strong> This is a practical course; the students will be able to use DL methods for solving real-world ML, CV, and NLP problems.</p>
<h2 id="schedule">Schedule</h2>
<ul>
<li><p>Jan 24, Lecture 1</p>
<ul>
<li><p>Fundamental ML problems</p></li>
<li><p>Regression</p></li>
<li><p>Classification</p></li>
</ul></li>
<li><p>Jan 24, <strong>Homework 0</strong> is assigned.</p>
<ul>
<li><p><a href="https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/HM0/HM.pdf">Click here for the assignment</a></p></li>
<li><p>Submission is not required.</p></li>
<li><p>Deadline: finish it before the 1st Quiz. (Otherwise, you will probably fail.)</p></li>
</ul></li>
<li><p>Jan 24, <strong>Homework 1</strong> is assigned (available on Canvas).</p>
<ul>
<li>Submission: submit to Canvas.</li>
</ul></li>
<li><p>Jan 31, <strong>CANCELED</strong> due to the instructor's conference traveling</p></li>
<li><p>Feb 7, Lecture 2</p>
<ul>
<li><p>Classification (cont.)</p></li>
<li><p>Regularization</p></li>
</ul></li>
<li><p>Feb 14, Lecture 3</p>
<ul>
<li><p>Dimensionality reduction</p></li>
<li><p>Matrix computations</p></li>
<li><p>Neural network basics</p></li>
</ul></li>
<li><p>Feb 14, <strong>Homework 2</strong> is assigned (available on Canvas).</p>
<ul>
<li>Submission: submit to Canvas.</li>
</ul></li>
<li><p>Feb 21, Lecture 4</p>
<ul>
<li><p>Clustering</p></li>
<li><p>Keras</p></li>
<li><p>Preparation for Quiz</p></li>
<li><p>Convolutional neural networks</p></li>
</ul></li>
<li><p>Feb 24, <strong>Deadline for Homework 1</strong></p></li>
<li><p>Feb 28, <strong>Quiz</strong> (No lecture).</p>
<ul>
<li><p>Coverage: linear algebra, optimization, and ML basics.</p></li>
<li><p>Policy: No electronic device. Printed material is allowed.</p></li>
<li><p>Sample questions: [<a href="https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/Quiz1-Sample/Quiz.pdf">click here</a>]</p></li>
</ul></li>
<li><p>Mar 7, Lecture 5</p>
<ul>
<li>Convolutional neural networks (cont.)</li>
</ul></li>
<li><p>Mar 7, <strong>Homework 3</strong> is assigned</p>
<ul>
<li><p>Available at the course's repo [<a href="https://github.com/wangshusen/CS583A-2019Spring.git">click here</a>]</p></li>
<li><p>Submission: submit to Canvas.</p></li>
</ul></li>
<li><p>Extended to Mar 8 (originally Mar 7), <strong>Deadline for project proposal</strong></p>
<ul>
<li><p>Submission: Everyone must submit a proposal to Canvas, even if it is teamwork.</p></li>
<li><p>The finally participated competition is supposed be the same as in the proposal. If otherwise, convincing explanation and evidence must be provided in the project document to avoid penalty.</p></li>
</ul></li>
<li><p>Mar 14, Lecture 6</p>
<ul>
<li><p>Convolutional neural networks (cont.)</p></li>
<li><p>Autoencoders</p></li>
</ul></li>
<li><p>Mar 14, <strong>Deadline for Homework 2</strong></p></li>
<li><p>Mar 15, <strong>Homework 4 and Homework 5</strong> are assigned</p>
<ul>
<li><p>Available at the course's repo [<a href="https://github.com/wangshusen/CS583A-2019Spring.git">click here</a>]</p></li>
<li><p>Submission: submit to Canvas.</p></li>
</ul></li>
<li><p>Mar 21, Spring Break, no class</p></li>
<li><p>Mar 28, Lecture 7</p>
<ul>
<li><p>Autoencoders (cont.)</p></li>
<li><p>Recurrent neural networks</p></li>
</ul></li>
<li><p>Apr 4, Lecture 8</p>
<ul>
<li>Recurrent neural networks (cont.)</li>
</ul></li>
<li><p>Apr 7, <strong>Deadline for Homework 3</strong></p></li>
<li><p>Apr 11, Lecture 9</p>
<ul>
<li><p>Recurrent neural networks (cont.)</p></li>
<li><p>Optimization [<a href="https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Logistic/paper/logistic.pdf">read this</a>]</p></li>
</ul></li>
<li><p>Apr 18, Lecture 10</p>
<ul>
<li><p>Recommender system</p></li>
<li><p>Adversarial robustness</p></li>
<li><p>Review the Quiz</p></li>
</ul></li>
<li><p>Apr 21, <strong>Deadline for signing up for project presentation</strong></p>
<ul>
<li><p>Voluntary. Up to 5 bonus scores to the total.</p></li>
<li><p>Submission: submit to Canvas.</p></li>
<li><p>Selected at most 7 teams.</p></li>
<li><p>Selection criteria: Is the problem challenging? Does your method have novelty? Do you have good preliminary results? Can the audience learn anything from your presentation?</p></li>
</ul></li>
<li><p>Apr 25, Lecture 11</p>
<ul>
<li><p>GANs</p></li>
<li><p>Preparations for the final exam.</p></li>
</ul></li>
<li><p>May 1, <strong>Office Hours</strong></p>
<ul>
<li><span style="color:red">Time change: 3-5PM, May 2 ==&gt; 2-6PM, May 1</span></li>
</ul></li>
<li><p>May 2, <strong>Final Exam</strong></p>
<ul>
<li><p>Coverage: linear algebra, optimization, ML basics, neural network basics, CNN, RNN, Python programming, Keras, and content in the textbook. [<a href="https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/Coverage/coverage.pdf">Click here</a>] for the list.</p></li>
<li><p>Sample questions: [<a href="https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/Final-Sample/Final-Sample.pdf">click here</a>]</p></li>
<li><p>Policy: No electronic device (except for electronic calculator). Printed material is allowed.</p></li>
</ul></li>
<li><p>May 4, <strong>Deadline for Homework 4</strong> (Extended to May 11)</p></li>
<li><p>May 5, <strong>Deadline for Homework 5</strong> (Extended to May 11)</p></li>
<li><p>May 7, 3:00 to 5:00 PM, Office Hours</p>
<ul>
<li>Students can check their exam papers.</li>
</ul></li>
<li><p>May 8, 3:00 to 5:00 PM, Office Hours</p>
<ul>
<li>Students can check their exam papers.</li>
</ul></li>
<li><p>May 9, Office Hours <strong>Canceled</strong> due to the faculty retreat.</p></li>
<li><p>May 9, <strong>Project Presentation</strong></p>
<ul>
<li><p>Time and location: the same as the class.</p></li>
<li><p>The selected groups are required to attend.</p></li>
<li><p>If you are confident that you will get A without the bonus, you can email the instructor to cancel your presentation. But the cancelation request must be made 48 hours prior to the presentation to avoid penalty.</p></li>
</ul></li>
<li><p>May 19, <strong>Deadline for Course Project</strong></p>
<ul>
<li>Submission: submit to Canvas.</li>
</ul></li>
</ul>
<h2 id="syllabus-and-slides">Syllabus and Slides</h2>
<ol style="list-style-type: decimal">
<li><p><strong>Machine learning basics.</strong> This part briefly introduces the fundamental ML problems-- regression, classification, dimensionality reduction, and clustering-- and the traditional ML models and numerical algorithms for solving the problems.</p>
<ul>
<li><p>ML basics. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/1_ML_Basics.pdf">slides</a>]</p></li>
<li><p>Regression. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/2_Regression_1.pdf">slides-1</a>] [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/2_Regression_2.pdf">slides-2</a>]</p></li>
<li><p>Classification.</p>
<ul>
<li><p>Logistic regression: [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/3_Classification_1.pdf">slides</a>] [<a href="https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Logistic/paper/logistic.pdf">lecture note</a>]</p></li>
<li><p>SVM: [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/3_Classification_2.pdf">slides</a>]</p></li>
<li><p>Softmax classifier: [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/3_Classification_3.pdf">slides</a>]</p></li>
<li><p>KNN classifier: [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/3_Classification_4.pdf">slides</a>]</p></li>
</ul></li>
<li><p>Regularizations. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/3_Optimization.pdf">slides-1</a>][<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/3_Regularizations.pdf">slides-2</a>]</p></li>
<li><p>Clustering. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/4_Clustering.pdf">slides</a>]</p></li>
<li><p>Dimensionality reduction. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/5_DR_1.pdf">slides-1</a>] [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/5_DR_2.pdf">slides-2</a>]</p></li>
<li><p>Scientific computing libraries. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/5_DR_3.pdf">slides</a>]</p></li>
</ul></li>
<li><p><strong>Neural network basics.</strong> This part covers the multilayer perceptron, backpropagation, and deep learning libraries, with focus on Keras.</p>
<ul>
<li><p>Multilayer perceptron and backpropagation. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/6_NeuralNet_1.pdf">slides</a>]</p></li>
<li><p>Keras. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/6_NeuralNet_2.pdf">slides</a>]</p></li>
<li><p>Further reading:</p>
<ul>
<li><p>[<a href="https://adl1995.github.io/an-overview-of-activation-functions-used-in-neural-networks.html">activation functions</a>]</p></li>
<li><p>[<a href="https://isaacchanghau.github.io/post/loss_functions/">loss functions</a>]</p></li>
<li><p>[<a href="https://isaacchanghau.github.io/post/weight_initialization/">parameter initialization</a>]</p></li>
<li><p>[<a href="https://isaacchanghau.github.io/post/parameters_update/">optimization algorithms</a>]</p></li>
</ul></li>
</ul></li>
<li><p><strong>Convolutional neural networks (CNNs).</strong> This part is focused on CNNs and its application to computer vision problems.</p>
<ul>
<li><p>CNN basics. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/7_CNN_1.pdf">slides</a>]</p></li>
<li><p>Tricks for improving test accuracy. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/7_CNN_2.pdf">slides</a>]</p></li>
<li><p>Feature scaling and batch normalization. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/7_CNN_3.pdf">slides</a>]</p></li>
<li><p>Advanced topics on CNNs. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/7_CNN_4.pdf">slides</a>]</p></li>
<li><p>Popular CNN architectures. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/7_CNN_5.pdf">slides</a>]</p></li>
<li><p>Face recognition. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/7_CNN_6.pdf">slides</a>]</p></li>
<li><p>Further reading:</p>
<ul>
<li><p>[style transfer (Section 8.1, Chollet's book)]</p></li>
<li><p>[visualize CNN (Section 5.4, Chollet's book)]</p></li>
</ul></li>
</ul></li>
<li><p><strong>Autoencoders.</strong> This part introduces autoencoders for dimensionality reduction and image generation.</p>
<ul>
<li><p>Autoencoder for dimensionality reduction. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/8_AE_1.pdf">slides</a>]</p></li>
<li><p>Variational Autoencoders (VAEs) for image generation. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/8_AE_2.pdf">slides</a>]</p></li>
</ul></li>
<li><p><strong>Recurrent neural networks (RNNs).</strong> This part introduces RNNs and its applications in natural language processing (NLP).</p>
<ul>
<li><p>Text processing. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_1.pdf">slides</a>]</p></li>
<li><p>RNN basics and LSTM. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_2.pdf">slides</a>][<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">reference</a>]</p></li>
<li><p>Text generation. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_3.pdf">slides</a>]</p></li>
<li><p>Machine translation. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_4.pdf">slides</a>]</p></li>
<li><p>Image caption generation. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_5.pdf">slides</a>][<a href="https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/">reference</a>]</p></li>
<li><p>Attention. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_6.pdf">slides</a>][<a href="https://distill.pub/2016/augmented-rnns/">reference-1</a>] [<a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">reference-2</a>]</p></li>
<li><p>Transformer model: beyond RNNs. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_7.pdf">slides</a>][<a href="https://arxiv.org/pdf/1706.03762.pdf">reference</a>]</p></li>
<li><p>Further reading:</p>
<ul>
<li><p>[<a href="http://www.aclweb.org/anthology/D14-1162">GloVe: Global Vectors for Word Representation</a>]</p></li>
<li><p>[<a href="https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf">Neural Word Embedding as Implicit Matrix Factorization</a>]</p></li>
</ul></li>
</ul></li>
<li><p><strong>Recommender system.</strong> This part is focused on the collaborative filtering approach to recommendation based on the user-item rating data. This part covers matrix completion methods and neural network approaches.</p>
<ul>
<li>Collaborative filtering. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/10_Recommender.pdf">slides</a>]</li>
</ul></li>
<li><p><strong>Adversarial Robustness.</strong> This part introduces how to attack neural networks using adversarial examples and how to defend from the attack.</p>
<ul>
<li><p>White box attack and defend. [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/11_Adversarial.pdf">slides</a>]</p></li>
<li><p>Further reading: [<a href="https://adversarial-ml-tutorial.org/">Adversarial Robustness - Theory and Practice</a>]</p></li>
</ul></li>
<li><p><strong>Generative Adversarial Networks (GANs).</strong></p>
<ul>
<li>DC-GAN [<a href="https://github.com/wangshusen/DeepLearning/blob/master/Slides/12_GAN.pdf">slides</a>]</li>
</ul></li>
</ol>
<h2 id="project">Project</h2>
<p>Every student must participate in one <a href="https://www.kaggle.com/competitions">Kaggle competition</a>.</p>
<ul>
<li><p><strong>Details</strong>: [<a href="https://github.com/wangshusen/CS583A-2019Spring/blob/master/project/Project/proj.pdf">click here</a>]</p></li>
<li><p><strong>Teamwork policy</strong>: You had better work on your own project. Teamwork (up to 3 students) is allowed if the competition has a heavy workload; the workload and team size will be considered in the grading.</p></li>
<li><p><strong>Grading policy</strong>: See the evaluation form [<a href="https://github.com/wangshusen/CS583A-2019Spring/blob/master/project/Evaluation/Evaluation.pdf">click here</a>]. An OK but not excellent work typically lose 3 points.</p></li>
</ul>
<h2 id="textbooks">Textbooks</h2>
<p><strong>Required</strong>:</p>
<ul>
<li>Francois Chollet. Deep learning with Python. Manning Publications Co., 2017. (Available online.)</li>
</ul>
<p><strong>Recommended</strong>:</p>
<ul>
<li><p>Y. Nesterov. Introductory Lectures on Convex Optimization Book. Springer, 2013. (Available online.)</p></li>
<li><p>D. S. Watkins. Fundamentals of Matrix Computations. John Wiley &amp; Sons, 2004.</p></li>
<li><p>I. Goodfellow, Y. Bengio, A. Courville, Y. Bengio. Deep learning. MIT press, 2016. (Available online.)</p></li>
<li><p>M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of machine learning. MIT press, 2012.</p></li>
<li><p>J. Friedman, T. Hastie, and R. Tibshirani. The elements of statistical learning. Springer series in statistics, 2001. (Available online.)</p></li>
</ul>
<h2 id="grading-policy">Grading Policy</h2>
<p><strong>Grading percentages</strong>:</p>
<ul>
<li><p>Homework 50%</p></li>
<li><p>Final 15%</p></li>
<li><p>Project 20%</p></li>
<li><p>Quizzes 15%</p></li>
<li><p>Bonus (up to 10%)</p></li>
</ul>
<p><strong>Late penalty</strong>:</p>
<ul>
<li><p>Late submissions of assignments or project document for whatever reason will be punished. 1% of the score of an assignment/project will be deducted per day. For example, if an assignment is submitted 15 days and 1 minute later than the deadline (counted as 16 days) and it gets a grade of 95%, then the score after the deduction will be: 95% - 16% = 79%.</p></li>
<li><p>May 20 (not June 1 any more) is the firm deadline for all the homework and the course project. Submissions later than May 20 will not be graded.</p></li>
</ul>
</body>
</html>
